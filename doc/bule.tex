\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
%%\NeedsTeXFormat{LaTeX2e}
%%\documentclass{new_tlp}
\input{header.tex}

\title{ SAT Programming}
\author{\IEEEauthorblockN{Jean Christoph Jung}
\IEEEauthorblockA{\textit{Universit\"at Bremen} \\ Bremen, Germany} \and
Valentin Mayer-Eichberger \\
\IEEEauthorblockA{\textit{Technische Universit\"at Berlin} \\ Berlin, Germany} \and
Abdallah Saffidine \\
\IEEEauthorblockA{\textit{University of New South Wales} \\ Sydney, Australia}
}

\newcommand{\abd}[1]{\textcolor[rgb]{1.00,0.00,0.00}{(abd: #1).} }
\newcommand{\vale}[1]{\textcolor[rgb]{1.00,0.00,0.0}{(vale: #1). } }
\newcommand{\jean}[1]{\textcolor[rgb]{1.00,0.00,0.80}{(jean: #1). } }

\begin{document}

\maketitle

\newcommand{\bflat}{\ensuremath{\text{Bule}_\text{flat}}\xspace}
\newcommand{\bcore}{\ensuremath{\text{Bule}_\text{core}}\xspace}
\newcommand{\bfull}{\ensuremath{\text{Bule}_\text{full}}\xspace}
\newcommand{\bnice}{\ensuremath{\text{Bule}_\text{nice}}\xspace}
\newcommand{\bule}{\ensuremath{\text{Bule}}\xspace}

\begin{abstract}
    SAT Programming extends SAT Solving by a declarative modelling language. 
    We propose Bule, a Logic Programming language, based on classical logic that introduces SAT Programming. 
    A ground program in Bule consist of a set of propositional clauses with meaningful literals. 
    The process of translating a non-ground program to propositional clauses is called grounding and is done by iterating over the domain of their variables. 
    The semantics of Bule is simpler than Answer Set Programming or First Order Logic with bounds.  
    Bule also offers techniques based on SAT Solving such as Approximate Model Counting and Quantified Boolean Formulae 
    and enriches such SAT related technologies by a uniform modelling language. 

    %This paper formally defines the language Bule, presents the implementation
    %through key examples and compares to alternative approaches. 


    % With rising usage of SAT solvers the challenge to translate problems to CNF is everywhere. 
    % Such  CNF formulas are usually generated by a problem specific algorithm, encodings of a digital Boolean circuit, translated from a more expressive language such as constraint programming or specified as a fragment of first order logic. 
    % When encodings are  presented in the literature the inner workings are often hidden in subscripts of variables and hard to decipher.

    % In this paper we propose the grounding language \emph{Bule} that is easy to
    % write and read, and helps to generate, reason and compare CNF encodings. 
    % We aim to simplify the approaches above and remove just enough layers between creating and implementing an encodings to facilitate prototyping and debugging. 
    % In this paper we formally define the language \emph{Bule}, compare it to alternative approaches Datalog, FO(ID) and ASP. 
    % Furthermore, we have implemented the grounder and show its usage through a case study.

\end{abstract}

\tableofcontents
\section{Introduction and Motivation}

Comparing Answer set programming and satisfiability solving. Key difference
according to \cite{Lierler17} is that ASP has a modelling language and a
grounder attached to it, whereas SAT is focused on problems stemming from
already ground problems. We will try to change that !


\section{Bule Syntax and Semantics}

\vale{has to be updated to the hierachy}
For didactic reasons, we define syntax and semantics of \bule in three stages. 
We start with a fully ground program without term variables in \bflat, which is essentially CNF with readable literals. 
The non-ground language \bcore contains the basic functionality of the modelling language. 
Third we present the complete language \bfull, that allows for several extensions to ease modeling. 

\begin{itemize}
    \item \bflat: 
        \begin{itemize}
            \item set of ground clauses with meaningful identifiers 
        \end{itemize}
    \item \bcore Non-ground language with clean semantics
        \begin{itemize}
            \item fully bound (i.e. all variables are bound by a positive generator) 
            \item Exponential compression in the arity of the variables. 
        \end{itemize}
    \item \bfull 
        \begin{itemize}
            \item All term variables still need to be bound! 
            \item Grounding fact definitions. 
            \item arithmetic (fully ground), exponential compression!
            \item ranges, exponential compression!
            \item iterators 
        \end{itemize}
    \item \bnice is just for modelling and close to the implementation. 
        \begin{itemize}
            \item Implicitly bound variables, i.e. variables can be free. 
            \item \ldots
        \end{itemize}
\end{itemize}

Orthogonal to this hierarchy is the hierarchy of quantifier levels. 


\subsection{\bflat}

A ground Bule program is a set of clauses with literals. 

\subsection{\bcore}

Let $\Sigma,\Omega$ be disjoint countably infinite sets of relation symbols.  
Each relation symbol $R\in \Sigma\cup\Omega$ has an associated arity $\mn{ar}(R)$.  
Let us further fix a countably infinite supply of constant symbols \mn{Con} and variable symbols $\mn{Var}$.  
An \emph{atom} is of the form $R(t_1,\ldots,t_n)$ for some $R\in \Sigma\cup\Omega$ and $t_1,\ldots,t_n\in\mn{Con}\cup\mn{Var}$ and $n=\mn{ar}(R)$. 
An atom $R(t_1,\ldots,t_n)$ is \emph{ground} if $t_1,\ldots,t_n\in\mn{Con}$; ground atoms are also called \emph{facts}. 
An atom $R(t_1,\ldots,t_n)$ is a \emph{$\Sigma$-atom} or an \emph{$\Omega$-atom} if $R\in \Sigma$ or $R\in \Omega$, respectively. 
A \emph{literal} is an atom $R(t_1,\ldots,t_n)$ or a negated atom $\neg R(t_1,\ldots,t_n)$. 
An \emph{instance} is a finite set of facts. A \emph{substitution} is a map $v:\mn{Var}\cup\mn{Con}\to\mn{Con}$ which is the identity on $\mn{Con}$, that is, $v(a)=a$, for all $a\in\mn{Con}$.
et $\Imc$ be an instance, $\alpha$ a Boolean formula over atoms, and $v$ a substitution. 

We define $\Dmc,v\models \alpha$ inductively as follows: 
%
\begin{align*}
  %
  \Imc,v & \models R(t_1,\ldots,t_n) && \text{if
  $R(v(t_1),\ldots,v(t_n))\in \Imc$} \\
  %
  \Imc, v& \models \neg \alpha && \text{if $\Imc,v\not\models \alpha$}
  \\
  %
  \Imc, v& \models \alpha \wedge \alpha' && \text{if $\Imc,v\models
  \alpha$ and $\Imc,v\models\alpha'$}
  %
\end{align*}
%
If $\Imc,v\models\alpha$, we call $v$ a \emph{model} of $\alpha$ over the instance \Imc. 
A \emph{clause} is a disjunction of literals.

A \emph{\bcore-program} is a pair $\Pi=(\Imc,\Pmc)$ where $\Imc$ is a finite set of facts and \Pmc is a set of rules of the form 
%
\[B_1, \ldots, B_k \Rightarrow L_1, \ldots, L_m\]
%
where $B_1,\ldots,B_k$ are $\Sigma$-atoms and $L_1,\ldots,L_m$ are $\Omega$-literals such that every variable that occurs in one of the $L_i$ does occur in one of the $B_i$.

The semantics of \bcore-programs $\Pi=(\Imc,\Pmc)$ is defined via groundings. 
More precisely, with every \bcore-program $\Pi=(\Imc,\Pmc)$, we associate a set $\mn{cl}(\Pi)$ of ground clauses as follows.  
For every rule $B_1,\ldots,B_k \Rightarrow L_1,\ldots, L_n\in\Pmc$ and every model $v$ of $B_1\wedge\ldots\wedge B_k$ in \Imc, $\mn{cl}(\Pi)$ contains the clause
%
\[v(L_1)\vee\ldots\vee v(L_n).\]
%
We say that $\Pi$ is \emph{satisfiable} if the set of clauses $\mn{cl}(\Pi)$ is satisfiable, that is, 
there is an instance $\Mmc$ such that $\Mmc,\emptyset \models\mn{cl}(\Pi)$ (note that $\mn{cl}(\Pi)$ is ground, so the empty substitution $\emptyset$ suffices).

{\color{red} Although \bcore is a relatively simple language, we can
already model natural problems with it. To distinguish $\Sigma$- and
$\Omega$-atoms we write them with parenthesis $p(\;\;\cdot)$ or brackets
$q[\;\;\cdot]$,
respectively.


\begin{example}
  
\end{example}

}


\subsection{\bfull}

We extend \bcore with \emph{extended instances}, \emph{iterators},
\emph{integers}, and \emph{implicit declarations} and define the
semantics by mapping to \bcore. We start with definitions. 

An \emph{extended instance \Jmc} is a union of an instance \Imc with a
a set of rules of the form
%
\[B_1,\ldots,B_k\Rightarrow B\]
%
where $B,B_1,\ldots,B_k$ are $\Sigma$-atoms and every variable that
occurs in $B$ occurs in one of the $B_i$. We further require that the
rules in \Jmc are acyclic in the sense that the graph $G_\Jmc = (V_\Jmc,E_\Jmc)$ is
acyclic, where $V_\Jmc$ is the set of all relation symbols that occur in
\Jmc and $(R,R')\in E_\Jmc$ if there is a rule
$B_1,\ldots,B_k\Rightarrow B$ where $B$ is an atom with relation
symbol $R'$ and some $B_i$ is an atom with relation symbol $R(\cdot)$.  

An extended \bcore-program is now a pair $\Pi=(\Jmc,\Pmc)$ where
$\Jmc$ is an extended instance and \Pmc a set of rules as above. Every
extended \bcore-program \emph{induces} a \bcore-program $(\Imc,\Pmc)$
via an inductive process as follows. Let $\Imc_0$ be the set of facts
in \Jmc, and define $\Imc_{i+1}$ from $\Imc_i$ by adding, for every
rule $B_1,\ldots,B_k\Rightarrow B\in \Jmc$ and every model $v$ of
$B_1\wedge \ldots \wedge B_k$ over $\Imc_i$, the fact $v(B)$ to
$\Imc_{i+1}$. Note that this process terminates due to acyclicity of
\Jmc; $\Imc$ is defined to be fixed point of the sequence $\Imc_n$. An
extended \bcore-program is satisfiable if the induced \bcore-program
is satisfiable. 

Extended \bcore-programs can be used to define auxiliary facts which
are often useful for modeling, e.g.~see the following example. 
%
\begin{example}
  %
  \textcolor{red}{TODO.}
  %
\end{example}


\subsection{\bnice}

To make it easier to define the semantics of \bfull we omitted the syntactic sugar. 
The language \bnice on the other hand contains all syntactic sugar and makes modelling very convenient.  
Features like: 

\begin{itemize}
  \item iterators of the form $c(I):dom[I]$
  \item ranges $dom[1..k]$ 
  \item implicit definition of term variables as in the clause $~c(I,J),b(I,J).$.
  \item simple arithmetic as in the rule $c(I,J),c(I+1,J).$ 
  \item more arithmetic as in the rule $ I== 0 \ldots Y^2, k[K] \Rightarrow c(I^K\%2).$
\end{itemize}

\section{Implementation Details}

\vale{Program transformations. Multiple stages of grounding. Conceptual algorithm with some states.}

\section{Application}

\subsection{$4x4$ NQueens as \bflat}

Flat Bule only contains grounded clauses. It's essentially a pretty print of CNF.

\begin{lstlisting}
q(1,1), q(1,2), q(1,3), q(1,4).
q(2,1), q(2,2), q(2,3), q(2,4).
q(3,1), q(3,2), q(3,3), q(3,4).
q(4,1), q(4,2), q(4,3), q(4,4).
q(1,1), q(2,1), q(3,1), q(4,1).
...
~q(1,1), ~q(2,1).
~q(1,1), ~q(3,1).
~q(1,1), ~q(4,1).
~q(2,1), ~q(3,1).
~q(2,1), ~q(4,1).
~q(3,1), ~q(4,1).
~q(1,2), ~q(2,2).
~q(1,2), ~q(3,2).
...
~q(3,4), ~q(3,4).
~q(4,4), ~q(4,4).
\end{lstlisting}

\subsection{Simplified $4x4$ NQueens as \bcore}

Only vertical and horizontal constraints.

\begin{lstlisting}
dom[1].dom[2]. dom[3]. dom[4]. 
ne[1,2]. ne[1,3]. ne[1,4]. ne[2,3]. ne[2,4]. ne[3,4].

% AtLeast one per row and column
dom[X] => q(X,1), q(X,2), q(X,3), q(X,4).
dom[Y] => q(1,Y), q(2,Y), q(3,Y), q(4,Y).

% Max one per row and column  
dom[Y],  ne[X1,X2] => ~q(X1,Y), ~q(X2,Y). 
dom[X],  ne[Y1,Y2] => ~q(X,Y1), ~q(X,Y2). 
\end{lstlisting}

\subsection{Generic NQueens in \bfull}

\begin{lstlisting}
dom[1..n]. 

dom[X] => q(X,Y) : dom[Y]. 
dom[Y] => q(X,Y) : dom[X].

% Max one per row and column  
X1 < X2 => ~q(X1,Y), ~q(X2,Y). 
Y1 < Y2 => ~q(X,Y1), ~q(X,Y2). 

% diagonals
X1 < X2, Y1 >= Y2, X1 + Y1 == X2 + Y2 => ~q(X1,Y1), ~q(X2,Y2). 
X1 < X2, Y1 <= Y2, X1 + Y2 == X2 + Y1 => ~q(X1,Y1), ~q(X2,Y2). 
\end{lstlisting}

To make it more compact we could leave the diagonals out. 

\subsection{Reachability}

Given a set of edges, the following program encodes reachability in the induced graph, i.e. 

\lstinputlisting{../examples/reachability.bul}

\subsection{Cardinality Encoding through Counters}

Bule does not have native cardinality constraints. 
The following encoding is easy to adapt to encode cardinality constraints in CNF 
It also showcases how the counter encoding by \cite{Sinz05} looks in Bule. 
Given the search atoms $element(1\ldots n)$, the counter encodings encodes enforces that there are exactly $k$  variables true .

\begin{lstlisting}
~count(I,J),  count(I+1,J).
 count(I-1,J-1), ~count(I,J).
~element(I), ~count(I-1,J-1), count(I,J).
 element(I), ~count(I,J),     count(I-1,J).

 count(0,0). ~count(0,1). count(n,k). ~count(n,k+1).
\end{lstlisting}

Removing the second last unit the clause set becomes an AtMost constraint ( respectively the last unit an AtLeast constraint). 
For $k=1$ the counter encoding resolves to the ladder encoding (cite Ian Gent). 

\subsection{Planning Problem}

Find a good planning problems. 
Sokoban might be too complicated. 
Is there a simpler one ? 

\subsection{Prime Game}

Here we show that Bule can be used to model PSPACE complete problems in QBF. 
We also show how to do LOG encoding.  

Two players choosing the bits of a 5 bit number from lowest to highest bit such that 
the second player wins if the number is prime and the first if it is not. 

We apply the adaptive LOG encoding here such that. This encoding translates
naturally to Bule. We introduce a generator fact {\verb bit(D,I,P)} that is the 
bit representation of the  number $D$ with the $I$s bit to 1 (resp. 0). 

\begin{lstlisting}
n[0..31]. d[0..4].
p[2]. p[3]. p[5]. p[7]. p[11]. p[13]. p[17]. p[19]. p[23]. p[29].

d[D], D#mod2 == 0 => #exist[D], m(D)?
d[D], D#mod2 == 1 => #forall[D], m(D)?

n[D], d[I] => bit[D,I,(D/(2**I))#mod2]. 
p[P] => ~m(I):bit[P,I,1], m(I):bit[P,I,0].
\end{lstlisting}

\subsection{Generalised Arc Consistency in Bule}

\begin{lstlisting}
%% clauseset given as cl[ID,Var,Polarity]. polarity 1 is positive, 0 negated. 
%% for example if clause 2 is 6 -3 0, that would be cl[2,3,1]. cl[2,6,0].
%% v[V], contains all variables V. 
%% c[C], contains all variables Cls IDs
a[0]. a[1]. 
v[V], a[A] => assign1(V,A)?
c[C], => assign1(V,A):cl[C,V,A]. 


\end{lstlisting}



\subsection{Approx Model Counting}

Find a cool probability problem where we define two SAT problems. 
One for the nominator, one for the denominator. 


\section{Complexity}

\abd{Analyse} and \jean{check}. 

\bflat only horn is P-Complete, \bflat NP-Complete, \bflat with a quantifier prefix block  is PSPACE-Complete?
\bcore : EXPTIME-Complete, with quantification  EXPSPACE?
\bfull : 2EXPTIME-Complete, with quantification  2EXPSPACE? 
\bnice : has lots of syntactic sugar to be used in modelling. 

\section{Related Works and Citations and Ideas}

ASP: Bule smoothly avoids the difficulty induced by stable models, minimal models, well-founded 
semantics and loop formulas. From a logic programming point of view we treat tight, stratified, normal logic programs?

\begin{itemize}
    \item Writing Declarative Specification for Clauses: \cite{Gebser16} 
        \begin{itemize}
            \item The proposed language is a syntactic alternative to \bcore
            \item It uses translation forth and back between ASP
            \item no complexity for non-ground language analysed. 
            \item Does not distinguish syntactically between grounding facts and search variables as we do. 
            \item \bnice provides convenient modelling support that their language does not have. Implicit variables for instances. 
        \end{itemize}
    \item Disjunctive Datalog, DLV \cite{Eiter97} or even just Datalog \cite{Gottlob89}
    \item Assat, translating ASP programs to SAT \cite{Lin04}
    \item \cite{Janhunen11}. Compact Translations of Non-disjunctive Answer Set
        Programs to Propositional Clauses
    \item FO(ID). First order logic with bounds (guards) \cite{Wittocx10}
    \item Predicate Logic as a modeling language. IDP System. \cite{Cat18}
    \item Answer Set Programming Lparse/Gringo \cite{Gebser15}, \cite{Ferraris05}
%    \item QBF Solvers \cite{Lonsing17,Tentrup15}
    \item Lazy Clause Generation Interleaving Grounding and Search \cite{Cat15}
    \item Relationship with Effectively Propositional Logic (EPL)? 
\end{itemize}

\bibliographystyle{plain}
\bibliography{main}

\end{document}
